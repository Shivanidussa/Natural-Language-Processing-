{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39f20188",
   "metadata": {},
   "source": [
    "## Scenario: Analyzing and Segregating News Headlines for **Sarcasm Detection**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71bae8e",
   "metadata": {},
   "source": [
    "Past studies in Sarcasm Detection mostly make use of Twitter datasets collected using hashtag based supervision but such datasets are noisy in terms of labels and language. Furthermore, many tweets are replies to other tweets and detecting sarcasm in these requires the availability of contextual tweets.\n",
    "\n",
    "To overcome the limitations related to noise in Twitter datasets, this News Headlines dataset for Sarcasm Detection is collected from two news website. TheOnion aims at producing sarcastic versions of current events and we collected all the headlines from News in Brief and News in Photos categories (which are sarcastic). We collect real (and non-sarcastic) news headlines from HuffPost.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3d321e",
   "metadata": {},
   "source": [
    "### **Dataset Description:**\n",
    "\n",
    "The data set contains the following attributes:\n",
    "\n",
    "- **is_sarcastic**: 1 if the record is sarcastic otherwise 0\n",
    "\n",
    "- **headline**: the headline of the news article\n",
    "\n",
    "- **article_link**: link to the original news article. Useful in collecting supplementary data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b245812",
   "metadata": {},
   "source": [
    "### **Tasks to be performed:**\n",
    "\n",
    "- Download the data set from Dropox and install dependencies\n",
    "- Import required libraries and load the dataset\n",
    "- Perform Exploratory Data Analysis (EDA)\n",
    " - Analyze the data using **Pandas Profiling** and record your observations\n",
    " - Use **Sweetviz** to visualize the columns present in the data set\n",
    " - Analze the target variable **is sarcastic**\n",
    "- Implement Text Pre-processing \n",
    "- Impelement TF-IDF Vectorizer\n",
    "- Split the data set into training and testing set using **train_test_split** function from sklearn\n",
    "- Model Building \n",
    " - Bernoulli Classifier\n",
    "- Model Evaluation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6aa1d395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries Imported..\n"
     ]
    }
   ],
   "source": [
    "#importing the libraries and load the dataset\n",
    "import spacy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category = FutureWarning)\n",
    "\n",
    "print(\"Libraries Imported..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be7b9dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the dataset\n",
    "df =  pd.read_json(r\"C:\\Users\\Shivani Dussa\\Downloads\\Sarcasm_Headlines_Dataset.json\",lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e76ea965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26709, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_link</th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://politics.theonion.com/boehner-just-wan...</td>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/jk-rowlin...</td>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        article_link  \\\n",
       "0  https://www.huffingtonpost.com/entry/versace-b...   \n",
       "1  https://www.huffingtonpost.com/entry/roseanne-...   \n",
       "2  https://local.theonion.com/mom-starting-to-fea...   \n",
       "3  https://politics.theonion.com/boehner-just-wan...   \n",
       "4  https://www.huffingtonpost.com/entry/jk-rowlin...   \n",
       "\n",
       "                                            headline  is_sarcastic  \n",
       "0  former versace store clerk sues over secret 'b...             0  \n",
       "1  the 'roseanne' revival catches up to our thorn...             0  \n",
       "2  mom starting to fear son's web series closest ...             1  \n",
       "3  boehner just wants wife to listen, not come up...             1  \n",
       "4  j.k. rowling wishes snape happy birthday in th...             0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "611e09e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These dataset tells us that headlines wheather it is sarcastic or not\n",
    "# sarcastic headlines are 1 and un sarcastic haedlines are 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf602537",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380f480f",
   "metadata": {},
   "source": [
    "### Analysing the data using pandas profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac98484",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "400dad2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['article_link', 'headline', 'is_sarcastic'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ee2c6d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    14985\n",
       "1    11724\n",
       "Name: is_sarcastic, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.is_sarcastic.value_counts()         # 14985 are non sarcatsic and 11724 are sarcastic looks like balanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdd0645c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentages for is_sarcastic values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    56.104684\n",
       "1    43.895316\n",
       "Name: is_sarcastic, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Percentages for is_sarcastic values')\n",
    "df.is_sarcastic.value_counts() * 100/df.shape[0]    # Non- sarcastic = 56,sarcastic = 43"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6496c209",
   "metadata": {},
   "source": [
    "### Checking for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64d3202e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "article_link    0\n",
       "headline        0\n",
       "is_sarcastic    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a371264b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_link</th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://politics.theonion.com/boehner-just-wan...</td>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/jk-rowlin...</td>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        article_link  \\\n",
       "0  https://www.huffingtonpost.com/entry/versace-b...   \n",
       "1  https://www.huffingtonpost.com/entry/roseanne-...   \n",
       "2  https://local.theonion.com/mom-starting-to-fea...   \n",
       "3  https://politics.theonion.com/boehner-just-wan...   \n",
       "4  https://www.huffingtonpost.com/entry/jk-rowlin...   \n",
       "\n",
       "                                            headline  is_sarcastic  \n",
       "0  former versace store clerk sues over secret 'b...             0  \n",
       "1  the 'roseanne' revival catches up to our thorn...             0  \n",
       "2  mom starting to fear son's web series closest ...             1  \n",
       "3  boehner just wants wife to listen, not come up...             1  \n",
       "4  j.k. rowling wishes snape happy birthday in th...             0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ba3bd41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_link</th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "      <th>num_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://politics.theonion.com/boehner-just-wan...</td>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/jk-rowlin...</td>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        article_link  \\\n",
       "0  https://www.huffingtonpost.com/entry/versace-b...   \n",
       "1  https://www.huffingtonpost.com/entry/roseanne-...   \n",
       "2  https://local.theonion.com/mom-starting-to-fea...   \n",
       "3  https://politics.theonion.com/boehner-just-wan...   \n",
       "4  https://www.huffingtonpost.com/entry/jk-rowlin...   \n",
       "\n",
       "                                            headline  is_sarcastic  num_words  \n",
       "0  former versace store clerk sues over secret 'b...             0         12  \n",
       "1  the 'roseanne' revival catches up to our thorn...             0         14  \n",
       "2  mom starting to fear son's web series closest ...             1         14  \n",
       "3  boehner just wants wife to listen, not come up...             1         13  \n",
       "4  j.k. rowling wishes snape happy birthday in th...             0         11  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the headline number of words\n",
    "df['num_words'] = df['headline'].apply(lambda x: len(str(x).split()))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cfa9d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"former versace store clerk sues over secret 'black code' for minority shoppers\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0,'headline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc40de62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum no of words: 39\n"
     ]
    }
   ],
   "source": [
    "maxWords = df['num_words'].max()\n",
    "print(\"maximum no of words:\",maxWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6d4174b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_link</th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "      <th>num_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15247</th>\n",
       "      <td>https://www.theonion.com/elmore-leonard-modern...</td>\n",
       "      <td>elmore leonard, modern prose master, noted for...</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            article_link  \\\n",
       "15247  https://www.theonion.com/elmore-leonard-modern...   \n",
       "\n",
       "                                                headline  is_sarcastic  \\\n",
       "15247  elmore leonard, modern prose master, noted for...             1   \n",
       "\n",
       "       num_words  \n",
       "15247         39  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxtext =  df[df['num_words'] == 39]\n",
    "maxtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e46f622d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'elmore leonard, modern prose master, noted for his terse prose style and for writing about things perfectly and succinctly with a remarkable economy of words, unfortunately and sadly expired this gloomy tuesday at the age of 87 years old'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[15247,'headline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4e904d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df[df['num_words'] == maxWords]['headline'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9f2188f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['elmore leonard, modern prose master, noted for his terse prose style and for writing about things perfectly and succinctly with a remarkable economy of words, unfortunately and sadly expired this gloomy tuesday at the age of 87 years old'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(text))\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31f36692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elmore leonard, modern prose master, noted for his terse prose style and for writing about things perfectly and succinctly with a remarkable economy of words, unfortunately and sadly expired this gloomy tuesday at the age of 87 years old\n"
     ]
    }
   ],
   "source": [
    "print(text[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d94863",
   "metadata": {},
   "source": [
    "## Text Pre-proccesing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c472053",
   "metadata": {},
   "source": [
    "#### Word tokenize\n",
    "- A sentence or data split into words is called word tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f015c021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['elmore', 'leonard', ',', 'modern', 'prose', 'master', ',', 'noted', 'for', 'his', 'terse', 'prose', 'style', 'and', 'for', 'writing', 'about', 'things', 'perfectly', 'and', 'succinctly', 'with', 'a', 'remarkable', 'economy', 'of', 'words', ',', 'unfortunately', 'and', 'sadly', 'expired', 'this', 'gloomy', 'tuesday', 'at', 'the', 'age', 'of', '87', 'years', 'old']\n"
     ]
    }
   ],
   "source": [
    "#word tokenize\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "tokenCollection = nlp(text[0])\n",
    "\n",
    "#list compression method to get tokens\n",
    "tokenList = [token.text for token in tokenCollection]\n",
    "print(tokenList)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b8b23c",
   "metadata": {},
   "source": [
    "#### Punctuation\n",
    "Spacy library contains different punctuations, such as **Quotes, currency, punctuation** etc,\n",
    "In above sentence we have seen inveted comma punctuation in the sentence and it will be considered as new word token, which is not usefull for our analysis. So we will remove that punctuation from sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7239dca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quotes: [\"\\\\'\", '\"', '”', '“', '`', '‘', '´', '’', '‚', ',', '„', '»', '«', '「', '」', '『', '』', '（', '）', '〔', '〕', '【', '】', '《', '》', '〈', '〉']\n"
     ]
    }
   ],
   "source": [
    "# Data Preproccesing\n",
    "# Removing punctuation\n",
    "print('Quotes:',spacy.lang.punctuation.LIST_QUOTES)     # These are quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bea2308f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "punctuations: ['…', '……', ',', ':', ';', '\\\\!', '\\\\?', '¿', '؟', '¡', '\\\\(', '\\\\)', '\\\\[', '\\\\]', '\\\\{', '\\\\}', '<', '>', '_', '#', '\\\\*', '&', '。', '？', '！', '，', '、', '；', '：', '～', '·', '।', '،', '۔', '؛', '٪']\n"
     ]
    }
   ],
   "source": [
    "print('punctuations:',spacy.lang.punctuation.LIST_PUNCT)    # These are Punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c920a0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Currency: ['\\\\$', '£', '€', '¥', '฿', 'US\\\\$', 'C\\\\$', 'A\\\\$', '₽', '﷼', '₴', '₠', '₡', '₢', '₣', '₤', '₥', '₦', '₧', '₨', '₩', '₪', '₫', '€', '₭', '₮', '₯', '₰', '₱', '₲', '₳', '₴', '₵', '₶', '₷', '₸', '₹', '₺', '₻', '₼', '₽', '₾', '₿']\n"
     ]
    }
   ],
   "source": [
    "print('\\n Currency:',spacy.lang.punctuation.LIST_CURRENCY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "37dcfd2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Punctuation: [',', ',', ',']\n"
     ]
    }
   ],
   "source": [
    "#list  of punctuation contains most of punctuation, we will use only that for our analysis\n",
    "punct = [token.text for token in tokenCollection if token.is_punct]\n",
    "print('Punctuation:',punct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abe38f7",
   "metadata": {},
   "source": [
    "### Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3eb43d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stopwords is: -------------------- 326\n",
      "Ten stop words: ['onto', 'might', \"'ll\", 'may', 'did', 'her', '’ve', 'its', 'his', 'meanwhile']\n",
      "\n",
      " ************************************************************************************************************************ \n",
      "Stop Word in sentence: ['for', 'his', 'and', 'for', 'about', 'and', 'with', 'a', 'of', 'and', 'this', 'at', 'the', 'of']\n"
     ]
    }
   ],
   "source": [
    "# we will remove stopwords in dataset\n",
    "stopwords = list(spacy.lang.en.stop_words.STOP_WORDS)\n",
    "print('Number of stopwords is:','-'*20,len(stopwords))       #-*20 means its to print a line -----in a shortcut -*20\n",
    "print('Ten stop words:',list(stopwords[:10]))\n",
    "\n",
    "stop = [token.text for token in tokenCollection if token.is_stop]\n",
    "print('\\n','*'*120,'\\nStop Word in sentence:',stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac318d7",
   "metadata": {},
   "source": [
    "### Digit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "345926cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digits in sentence: ['87']\n"
     ]
    }
   ],
   "source": [
    "digit = [token.text for token in tokenCollection if token.is_digit]\n",
    "print('digits in sentence:',digit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ffb3a6",
   "metadata": {},
   "source": [
    "## Lemmatizing\n",
    "- Lemmetiztion is the process of retrieving the root word of the current word. Lemmatization is an essential process in NLP to bring different variants of a single word to one root word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aabc74f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['elmore', 'leonard', ',', 'modern', 'prose', 'master', ',', 'note', 'for', 'his', 'terse', 'prose', 'style', 'and', 'for', 'write', 'about', 'thing', 'perfectly', 'and', 'succinctly', 'with', 'a', 'remarkable', 'economy', 'of', 'word', ',', 'unfortunately', 'and', 'sadly', 'expire', 'this', 'gloomy', 'tuesday', 'at', 'the', 'age', 'of', '87', 'year', 'old']\n"
     ]
    }
   ],
   "source": [
    "lemma = [token.lemma_ for token in tokenCollection]\n",
    "print(lemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32605959",
   "metadata": {},
   "source": [
    "## Named Entities\n",
    "- A named entity is a \"real-world object\" that's assigned a name – for example, a person, a country, a product or a book title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f6c1a9b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">elmore leonard, modern prose master, noted for his terse prose style and for writing about things perfectly and succinctly with a remarkable economy of words, unfortunately and sadly expired this gloomy \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    tuesday\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " at \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the age of 87 years old\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spacy.displacy.render(tokenCollection, style = 'ent',jupyter = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9b871c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a9c25_row2_col6, #T_a9c25_row6_col6, #T_a9c25_row8_col5, #T_a9c25_row9_col5, #T_a9c25_row13_col5, #T_a9c25_row14_col5, #T_a9c25_row16_col5, #T_a9c25_row19_col5, #T_a9c25_row21_col5, #T_a9c25_row22_col5, #T_a9c25_row25_col5, #T_a9c25_row27_col6, #T_a9c25_row29_col5, #T_a9c25_row32_col5, #T_a9c25_row35_col5, #T_a9c25_row36_col5, #T_a9c25_row38_col5, #T_a9c25_row39_col7 {\n",
       "  background-color: orange;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a9c25\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_a9c25_level0_col0\" class=\"col_heading level0 col0\" >token</th>\n",
       "      <th id=\"T_a9c25_level0_col1\" class=\"col_heading level0 col1\" >lemma</th>\n",
       "      <th id=\"T_a9c25_level0_col2\" class=\"col_heading level0 col2\" >POS</th>\n",
       "      <th id=\"T_a9c25_level0_col3\" class=\"col_heading level0 col3\" >TAG</th>\n",
       "      <th id=\"T_a9c25_level0_col4\" class=\"col_heading level0 col4\" >DEP</th>\n",
       "      <th id=\"T_a9c25_level0_col5\" class=\"col_heading level0 col5\" >is_stopword</th>\n",
       "      <th id=\"T_a9c25_level0_col6\" class=\"col_heading level0 col6\" >is_punctuation</th>\n",
       "      <th id=\"T_a9c25_level0_col7\" class=\"col_heading level0 col7\" >is_digit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a9c25_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_a9c25_row0_col0\" class=\"data row0 col0\" >elmore</td>\n",
       "      <td id=\"T_a9c25_row0_col1\" class=\"data row0 col1\" >elmore</td>\n",
       "      <td id=\"T_a9c25_row0_col2\" class=\"data row0 col2\" >PROPN</td>\n",
       "      <td id=\"T_a9c25_row0_col3\" class=\"data row0 col3\" >NNP</td>\n",
       "      <td id=\"T_a9c25_row0_col4\" class=\"data row0 col4\" >advmod</td>\n",
       "      <td id=\"T_a9c25_row0_col5\" class=\"data row0 col5\" >False</td>\n",
       "      <td id=\"T_a9c25_row0_col6\" class=\"data row0 col6\" >False</td>\n",
       "      <td id=\"T_a9c25_row0_col7\" class=\"data row0 col7\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9c25_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_a9c25_row1_col0\" class=\"data row1 col0\" >leonard</td>\n",
       "      <td id=\"T_a9c25_row1_col1\" class=\"data row1 col1\" >leonard</td>\n",
       "      <td id=\"T_a9c25_row1_col2\" class=\"data row1 col2\" >PROPN</td>\n",
       "      <td id=\"T_a9c25_row1_col3\" class=\"data row1 col3\" >NNP</td>\n",
       "      <td id=\"T_a9c25_row1_col4\" class=\"data row1 col4\" >nsubj</td>\n",
       "      <td id=\"T_a9c25_row1_col5\" class=\"data row1 col5\" >False</td>\n",
       "      <td id=\"T_a9c25_row1_col6\" class=\"data row1 col6\" >False</td>\n",
       "      <td id=\"T_a9c25_row1_col7\" class=\"data row1 col7\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9c25_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_a9c25_row2_col0\" class=\"data row2 col0\" >,</td>\n",
       "      <td id=\"T_a9c25_row2_col1\" class=\"data row2 col1\" >,</td>\n",
       "      <td id=\"T_a9c25_row2_col2\" class=\"data row2 col2\" >PUNCT</td>\n",
       "      <td id=\"T_a9c25_row2_col3\" class=\"data row2 col3\" >,</td>\n",
       "      <td id=\"T_a9c25_row2_col4\" class=\"data row2 col4\" >punct</td>\n",
       "      <td id=\"T_a9c25_row2_col5\" class=\"data row2 col5\" >False</td>\n",
       "      <td id=\"T_a9c25_row2_col6\" class=\"data row2 col6\" >True</td>\n",
       "      <td id=\"T_a9c25_row2_col7\" class=\"data row2 col7\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9c25_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_a9c25_row3_col0\" class=\"data row3 col0\" >modern</td>\n",
       "      <td id=\"T_a9c25_row3_col1\" class=\"data row3 col1\" >modern</td>\n",
       "      <td id=\"T_a9c25_row3_col2\" class=\"data row3 col2\" >ADJ</td>\n",
       "      <td id=\"T_a9c25_row3_col3\" class=\"data row3 col3\" >JJ</td>\n",
       "      <td id=\"T_a9c25_row3_col4\" class=\"data row3 col4\" >amod</td>\n",
       "      <td id=\"T_a9c25_row3_col5\" class=\"data row3 col5\" >False</td>\n",
       "      <td id=\"T_a9c25_row3_col6\" class=\"data row3 col6\" >False</td>\n",
       "      <td id=\"T_a9c25_row3_col7\" class=\"data row3 col7\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9c25_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_a9c25_row4_col0\" class=\"data row4 col0\" >prose</td>\n",
       "      <td id=\"T_a9c25_row4_col1\" class=\"data row4 col1\" >prose</td>\n",
       "      <td id=\"T_a9c25_row4_col2\" class=\"data row4 col2\" >NOUN</td>\n",
       "      <td id=\"T_a9c25_row4_col3\" class=\"data row4 col3\" >NN</td>\n",
       "      <td id=\"T_a9c25_row4_col4\" class=\"data row4 col4\" >compound</td>\n",
       "      <td id=\"T_a9c25_row4_col5\" class=\"data row4 col5\" >False</td>\n",
       "      <td id=\"T_a9c25_row4_col6\" class=\"data row4 col6\" >False</td>\n",
       "      <td id=\"T_a9c25_row4_col7\" class=\"data row4 col7\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9c25_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_a9c25_row5_col0\" class=\"data row5 col0\" >master</td>\n",
       "      <td id=\"T_a9c25_row5_col1\" class=\"data row5 col1\" >master</td>\n",
       "      <td id=\"T_a9c25_row5_col2\" class=\"data row5 col2\" >NOUN</td>\n",
       "      <td id=\"T_a9c25_row5_col3\" class=\"data row5 col3\" >NN</td>\n",
       "      <td id=\"T_a9c25_row5_col4\" class=\"data row5 col4\" >appos</td>\n",
       "      <td id=\"T_a9c25_row5_col5\" class=\"data row5 col5\" >False</td>\n",
       "      <td id=\"T_a9c25_row5_col6\" class=\"data row5 col6\" >False</td>\n",
       "      <td id=\"T_a9c25_row5_col7\" class=\"data row5 col7\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9c25_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_a9c25_row6_col0\" class=\"data row6 col0\" >,</td>\n",
       "      <td id=\"T_a9c25_row6_col1\" class=\"data row6 col1\" >,</td>\n",
       "      <td id=\"T_a9c25_row6_col2\" class=\"data row6 col2\" >PUNCT</td>\n",
       "      <td id=\"T_a9c25_row6_col3\" class=\"data row6 col3\" >,</td>\n",
       "      <td id=\"T_a9c25_row6_col4\" class=\"data row6 col4\" >punct</td>\n",
       "      <td id=\"T_a9c25_row6_col5\" class=\"data row6 col5\" >False</td>\n",
       "      <td id=\"T_a9c25_row6_col6\" class=\"data row6 col6\" >True</td>\n",
       "      <td id=\"T_a9c25_row6_col7\" class=\"data row6 col7\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9c25_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_a9c25_row7_col0\" class=\"data row7 col0\" >noted</td>\n",
       "      <td id=\"T_a9c25_row7_col1\" class=\"data row7 col1\" >note</td>\n",
       "      <td id=\"T_a9c25_row7_col2\" class=\"data row7 col2\" >VERB</td>\n",
       "      <td id=\"T_a9c25_row7_col3\" class=\"data row7 col3\" >VBD</td>\n",
       "      <td id=\"T_a9c25_row7_col4\" class=\"data row7 col4\" >ROOT</td>\n",
       "      <td id=\"T_a9c25_row7_col5\" class=\"data row7 col5\" >False</td>\n",
       "      <td id=\"T_a9c25_row7_col6\" class=\"data row7 col6\" >False</td>\n",
       "      <td id=\"T_a9c25_row7_col7\" class=\"data row7 col7\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9c25_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_a9c25_row8_col0\" class=\"data row8 col0\" >for</td>\n",
       "      <td id=\"T_a9c25_row8_col1\" class=\"data row8 col1\" >for</td>\n",
       "      <td id=\"T_a9c25_row8_col2\" class=\"data row8 col2\" >SCONJ</td>\n",
       "      <td id=\"T_a9c25_row8_col3\" class=\"data row8 col3\" >IN</td>\n",
       "      <td id=\"T_a9c25_row8_col4\" class=\"data row8 col4\" >mark</td>\n",
       "      <td id=\"T_a9c25_row8_col5\" class=\"data row8 col5\" >True</td>\n",
       "      <td id=\"T_a9c25_row8_col6\" class=\"data row8 col6\" >False</td>\n",
       "      <td id=\"T_a9c25_row8_col7\" class=\"data row8 col7\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9c25_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_a9c25_row9_col0\" class=\"data row9 col0\" >his</td>\n",
       "      <td id=\"T_a9c25_row9_col1\" class=\"data row9 col1\" >his</td>\n",
       "      <td id=\"T_a9c25_row9_col2\" class=\"data row9 col2\" >PRON</td>\n",
       "      <td id=\"T_a9c25_row9_col3\" class=\"data row9 col3\" >PRP$</td>\n",
       "      <td id=\"T_a9c25_row9_col4\" class=\"data row9 col4\" >poss</td>\n",
       "      <td id=\"T_a9c25_row9_col5\" class=\"data row9 col5\" >True</td>\n",
       "      <td id=\"T_a9c25_row9_col6\" class=\"data row9 col6\" >False</td>\n",
       "      <td id=\"T_a9c25_row9_col7\" class=\"data row9 col7\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9c25_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_a9c25_row10_col0\" class=\"data row10 col0\" >terse</td>\n",
       "      <td id=\"T_a9c25_row10_col1\" class=\"data row10 col1\" >terse</td>\n",
       "      <td id=\"T_a9c25_row10_col2\" class=\"data row10 col2\" >ADJ</td>\n",
       "      <td id=\"T_a9c25_row10_col3\" class=\"data row10 col3\" >JJ</td>\n",
       "      <td id=\"T_a9c25_row10_col4\" class=\"data row10 col4\" >amod</td>\n",
       "      <td id=\"T_a9c25_row10_col5\" class=\"data row10 col5\" >False</td>\n",
       "      <td id=\"T_a9c25_row10_col6\" class=\"data row10 col6\" >False</td>\n",
       "      <td id=\"T_a9c25_row10_col7\" class=\"data row10 col7\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9c25_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_a9c25_row11_col0\" class=\"data row11 col0\" >prose</td>\n",
       "      <td id=\"T_a9c25_row11_col1\" class=\"data row11 col1\" >prose</td>\n",
       "      <td id=\"T_a9c25_row11_col2\" class=\"data row11 col2\" >VERB</td>\n",
       "      <td id=\"T_a9c25_row11_col3\" class=\"data row11 col3\" >VBP</td>\n",
       "      <td id=\"T_a9c25_row11_col4\" class=\"data row11 col4\" >advcl</td>\n",
       "      <td id=\"T_a9c25_row11_col5\" class=\"data row11 col5\" >False</td>\n",
       "      <td id=\"T_a9c25_row11_col6\" class=\"data row11 col6\" >False</td>\n",
       "      <td id=\"T_a9c25_row11_col7\" class=\"data row11 col7\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9c25_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_a9c25_row12_col0\" class=\"data row12 col0\" >style</td>\n",
       "      <td id=\"T_a9c25_row12_col1\" class=\"data row12 col1\" >style</td>\n",
       "      <td id=\"T_a9c25_row12_col2\" class=\"data row12 col2\" >NOUN</td>\n",
       "      <td id=\"T_a9c25_row12_col3\" class=\"data row12 col3\" >NN</td>\n",
       "      <td id=\"T_a9c25_row12_col4\" class=\"data row12 col4\" >dobj</td>\n",
       "      <td id=\"T_a9c25_row12_col5\" class=\"data row12 col5\" >False</td>\n",
       "      <td id=\"T_a9c25_row12_col6\" class=\"data row12 col6\" >False</td>\n",
       "      <td id=\"T_a9c25_row12_col7\" class=\"data row12 col7\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9c25_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_a9c25_row13_col0\" class=\"data row13 col0\" >and</td>\n",
       "      <td id=\"T_a9c25_row13_col1\" class=\"data row13 col1\" >and</td>\n",
       "      <td id=\"T_a9c25_row13_col2\" class=\"data row13 col2\" >CCONJ</td>\n",
       "      <td id=\"T_a9c25_row13_col3\" class=\"data row13 col3\" >CC</td>\n",
       "      <td id=\"T_a9c25_row13_col4\" class=\"data row13 col4\" >cc</td>\n",
       "      <td id=\"T_a9c25_row13_col5\" class=\"data row13 col5\" >True</td>\n",
       "      <td id=\"T_a9c25_row13_col6\" class=\"data row13 col6\" >False</td>\n",
       "      <td id=\"T_a9c25_row13_col7\" class=\"data row13 col7\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9c25_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_a9c25_row14_col0\" class=\"data row14 col0\" >for</td>\n",
       "      <td id=\"T_a9c25_row14_col1\" class=\"data row14 col1\" >for</td>\n",
       "      <td id=\"T_a9c25_row14_col2\" class=\"data row14 col2\" >ADP</td>\n",
       "      <td id=\"T_a9c25_row14_col3\" class=\"data row14 col3\" >IN</td>\n",
       "      <td id=\"T_a9c25_row14_col4\" class=\"data row14 col4\" >prep</td>\n",
       "      <td id=\"T_a9c25_row14_col5\" class=\"data row14 col5\" >True</td>\n",
       "      <td id=\"T_a9c25_row14_col6\" class=\"data row14 col6\" >False</td>\n",
       "      <td id=\"T_a9c25_row14_col7\" class=\"data row14 col7\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9c25_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_a9c25_row15_col0\" class=\"data row15 col0\" >writing</td>\n",
       "      <td id=\"T_a9c25_row15_col1\" class=\"data row15 col1\" >write</td>\n",
       "      <td id=\"T_a9c25_row15_col2\" class=\"data row15 col2\" >VERB</td>\n",
       "      <td id=\"T_a9c25_row15_col3\" class=\"data row15 col3\" >VBG</td>\n",
       "      <td id=\"T_a9c25_row15_col4\" class=\"data row15 col4\" >pcomp</td>\n",
       "      <td id=\"T_a9c25_row15_col5\" class=\"data row15 col5\" >False</td>\n",
       "      <td id=\"T_a9c25_row15_col6\" class=\"data row15 col6\" >False</td>\n",
       "      <td id=\"T_a9c25_row15_col7\" class=\"data row15 col7\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9c25_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_a9c25_row16_col0\" class=\"data row16 col0\" >about</td>\n",
       "      <td id=\"T_a9c25_row16_col1\" class=\"data row16 col1\" >about</td>\n",
       "      <td id=\"T_a9c25_row16_col2\" class=\"data row16 col2\" >ADP</td>\n",
       "      <td id=\"T_a9c25_row16_col3\" class=\"data row16 col3\" >IN</td>\n",
       "      <td id=\"T_a9c25_row16_col4\" class=\"data row16 col4\" >prep</td>\n",
       "      <td id=\"T_a9c25_row16_col5\" class=\"data row16 col5\" >True</td>\n",
       "      <td id=\"T_a9c25_row16_col6\" class=\"data row16 col6\" >False</td>\n",
       "      <td id=\"T_a9c25_row16_col7\" class=\"data row16 col7\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9c25_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_a9c25_row17_col0\" class=\"data row17 col0\" >things</td>\n",
       "      <td id=\"T_a9c25_row17_col1\" class=\"data row17 col1\" >thing</td>\n",
       "      <td id=\"T_a9c25_row17_col2\" class=\"data row17 col2\" >NOUN</td>\n",
       "      <td id=\"T_a9c25_row17_col3\" class=\"data row17 col3\" >NNS</td>\n",
       "      <td id=\"T_a9c25_row17_col4\" class=\"data row17 col4\" >pobj</td>\n",
       "      <td id=\"T_a9c25_row17_col5\" class=\"data row17 col5\" >False</td>\n",
       "      <td id=\"T_a9c25_row17_col6\" class=\"data row17 col6\" >False</td>\n",
       "      <td id=\"T_a9c25_row17_col7\" class=\"data row17 col7\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9c25_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_a9c25_row18_col0\" class=\"data row18 col0\" >perfectly</td>\n",
       "      <td id=\"T_a9c25_row18_col1\" class=\"data row18 col1\" >perfectly</td>\n",
       "      <td id=\"T_a9c25_row18_col2\" class=\"data row18 col2\" >ADV</td>\n",
       "      <td id=\"T_a9c25_row18_col3\" class=\"data row18 col3\" >RB</td>\n",
       "      <td id=\"T_a9c25_row18_col4\" class=\"data row18 col4\" >advmod</td>\n",
       "      <td id=\"T_a9c25_row18_col5\" class=\"data row18 col5\" >False</td>\n",
       "      <td id=\"T_a9c25_row18_col6\" class=\"data row18 col6\" >False</td>\n",
       "      <td id=\"T_a9c25_row18_col7\" class=\"data row18 col7\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9c25_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_a9c25_row19_col0\" class=\"data row19 col0\" >and</td>\n",
       "      <td id=\"T_a9c25_row19_col1\" class=\"data row19 col1\" >and</td>\n",
       "      <td id=\"T_a9c25_row19_col2\" class=\"data row19 col2\" >CCONJ</td>\n",
       "      <td id=\"T_a9c25_row19_col3\" class=\"data row19 col3\" >CC</td>\n",
       "      <td id=\"T_a9c25_row19_col4\" class=\"data row19 col4\" >cc</td>\n",
       "      <td id=\"T_a9c25_row19_col5\" class=\"data row19 col5\" >True</td>\n",
       "      <td id=\"T_a9c25_row19_col6\" class=\"data row19 col6\" >False</td>\n",
       "      <td id=\"T_a9c25_row19_col7\" class=\"data row19 col7\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9c25_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_a9c25_row20_col0\" class=\"data row20 col0\" >succinctly</td>\n",
       "      <td id=\"T_a9c25_row20_col1\" class=\"data row20 col1\" >succinctly</td>\n",
       "      <td id=\"T_a9c25_row20_col2\" class=\"data row20 col2\" >ADV</td>\n",
       "      <td id=\"T_a9c25_row20_col3\" class=\"data row20 col3\" >RB</td>\n",
       "      <td id=\"T_a9c25_row20_col4\" class=\"data row20 col4\" >conj</td>\n",
       "      <td id=\"T_a9c25_row20_col5\" class=\"data row20 col5\" >False</td>\n",
       "      <td id=\"T_a9c25_row20_col6\" class=\"data row20 col6\" >False</td>\n",
       "      <td id=\"T_a9c25_row20_col7\" class=\"data row20 col7\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9c25_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_a9c25_row21_col0\" class=\"data row21 col0\" >with</td>\n",
       "      <td id=\"T_a9c25_row21_col1\" class=\"data row21 col1\" >with</td>\n",
       "      <td id=\"T_a9c25_row21_col2\" class=\"data row21 col2\" >ADP</td>\n",
       "      <td id=\"T_a9c25_row21_col3\" class=\"data row21 col3\" >IN</td>\n",
       "      <td id=\"T_a9c25_row21_col4\" class=\"data row21 col4\" >prep</td>\n",
       "      <td id=\"T_a9c25_row21_col5\" class=\"data row21 col5\" >True</td>\n",
       "      <td id=\"T_a9c25_row21_col6\" class=\"data row21 col6\" >False</td>\n",
       "      <td id=\"T_a9c25_row21_col7\" class=\"data row21 col7\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9c25_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_a9c25_row22_col0\" class=\"data row22 col0\" >a</td>\n",
       "      <td id=\"T_a9c25_row22_col1\" class=\"data row22 col1\" >a</td>\n",
       "      <td id=\"T_a9c25_row22_col2\" class=\"data row22 col2\" >DET</td>\n",
       "      <td id=\"T_a9c25_row22_col3\" class=\"data row22 col3\" >DT</td>\n",
       "      <td id=\"T_a9c25_row22_col4\" class=\"data row22 col4\" >det</td>\n",
       "      <td id=\"T_a9c25_row22_col5\" class=\"data row22 col5\" >True</td>\n",
       "      <td id=\"T_a9c25_row22_col6\" class=\"data row22 col6\" >False</td>\n",
       "      <td id=\"T_a9c25_row22_col7\" class=\"data row22 col7\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9c25_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_a9c25_row23_col0\" class=\"data row23 col0\" >remarkable</td>\n",
       "      <td id=\"T_a9c25_row23_col1\" class=\"data row23 col1\" >remarkable</td>\n",
       "      <td id=\"T_a9c25_row23_col2\" class=\"data row23 col2\" >ADJ</td>\n",
       "      <td id=\"T_a9c25_row23_col3\" class=\"data row23 col3\" >JJ</td>\n",
       "      <td id=\"T_a9c25_row23_col4\" class=\"data row23 col4\" >amod</td>\n",
       "      <td id=\"T_a9c25_row23_col5\" class=\"data row23 col5\" >False</td>\n",
       "      <td id=\"T_a9c25_row23_col6\" class=\"data row23 col6\" >False</td>\n",
       "      <td id=\"T_a9c25_row23_col7\" class=\"data row23 col7\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9c25_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "      <td id=\"T_a9c25_row24_col0\" class=\"data row24 col0\" >economy</td>\n",
       "      <td id=\"T_a9c25_row24_col1\" class=\"data row24 col1\" >economy</td>\n",
       "      <td id=\"T_a9c25_row24_col2\" class=\"data row24 col2\" >NOUN</td>\n",
       "      <td id=\"T_a9c25_row24_col3\" class=\"data row24 col3\" >NN</td>\n",
       "      <td id=\"T_a9c25_row24_col4\" class=\"data row24 col4\" >pobj</td>\n",
       "      <td id=\"T_a9c25_row24_col5\" class=\"data row24 col5\" >False</td>\n",
       "      <td id=\"T_a9c25_row24_col6\" class=\"data row24 col6\" >False</td>\n",
       "      <td id=\"T_a9c25_row24_col7\" class=\"data row24 col7\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9c25_level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
       "      <td id=\"T_a9c25_row25_col0\" class=\"data row25 col0\" >of</td>\n",
       "      <td id=\"T_a9c25_row25_col1\" class=\"data row25 col1\" >of</td>\n",
       "      <td id=\"T_a9c25_row25_col2\" class=\"data row25 col2\" >ADP</td>\n",
       "      <td id=\"T_a9c25_row25_col3\" class=\"data row25 col3\" >IN</td>\n",
       "      <td id=\"T_a9c25_row25_col4\" class=\"data row25 col4\" >prep</td>\n",
       "      <td id=\"T_a9c25_row25_col5\" class=\"data row25 col5\" >True</td>\n",
       "      <td id=\"T_a9c25_row25_col6\" class=\"data row25 col6\" >False</td>\n",
       "      <td id=\"T_a9c25_row25_col7\" class=\"data row25 col7\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9c25_level0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
       "      <td id=\"T_a9c25_row26_col0\" class=\"data row26 col0\" >words</td>\n",
       "      <td id=\"T_a9c25_row26_col1\" class=\"data row26 col1\" >word</td>\n",
       "      <td id=\"T_a9c25_row26_col2\" class=\"data row26 col2\" >NOUN</td>\n",
       "      <td id=\"T_a9c25_row26_col3\" class=\"data row26 col3\" >NNS</td>\n",
       "      <td id=\"T_a9c25_row26_col4\" class=\"data row26 col4\" >pobj</td>\n",
       "      <td id=\"T_a9c25_row26_col5\" class=\"data row26 col5\" >False</td>\n",
       "      <td id=\"T_a9c25_row26_col6\" class=\"data row26 col6\" >False</td>\n",
       "      <td id=\"T_a9c25_row26_col7\" class=\"data row26 col7\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9c25_level0_row27\" class=\"row_heading level0 row27\" >27</th>\n",
       "      <td id=\"T_a9c25_row27_col0\" class=\"data row27 col0\" >,</td>\n",
       "      <td id=\"T_a9c25_row27_col1\" class=\"data row27 col1\" >,</td>\n",
       "      <td id=\"T_a9c25_row27_col2\" class=\"data row27 col2\" >PUNCT</td>\n",
       "      <td id=\"T_a9c25_row27_col3\" class=\"data row27 col3\" >,</td>\n",
       "      <td id=\"T_a9c25_row27_col4\" class=\"data row27 col4\" >punct</td>\n",
       "      <td id=\"T_a9c25_row27_col5\" class=\"data row27 col5\" >False</td>\n",
       "      <td id=\"T_a9c25_row27_col6\" class=\"data row27 col6\" >True</td>\n",
       "      <td id=\"T_a9c25_row27_col7\" class=\"data row27 col7\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9c25_level0_row28\" class=\"row_heading level0 row28\" >28</th>\n",
       "      <td id=\"T_a9c25_row28_col0\" class=\"data row28 col0\" >unfortunately</td>\n",
       "      <td id=\"T_a9c25_row28_col1\" class=\"data row28 col1\" >unfortunately</td>\n",
       "      <td id=\"T_a9c25_row28_col2\" class=\"data row28 col2\" >ADV</td>\n",
       "      <td id=\"T_a9c25_row28_col3\" class=\"data row28 col3\" >RB</td>\n",
       "      <td id=\"T_a9c25_row28_col4\" class=\"data row28 col4\" >advmod</td>\n",
       "      <td id=\"T_a9c25_row28_col5\" class=\"data row28 col5\" >False</td>\n",
       "      <td id=\"T_a9c25_row28_col6\" class=\"data row28 col6\" >False</td>\n",
       "      <td id=\"T_a9c25_row28_col7\" class=\"data row28 col7\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9c25_level0_row29\" class=\"row_heading level0 row29\" >29</th>\n",
       "      <td id=\"T_a9c25_row29_col0\" class=\"data row29 col0\" >and</td>\n",
       "      <td id=\"T_a9c25_row29_col1\" class=\"data row29 col1\" >and</td>\n",
       "      <td id=\"T_a9c25_row29_col2\" class=\"data row29 col2\" >CCONJ</td>\n",
       "      <td id=\"T_a9c25_row29_col3\" class=\"data row29 col3\" >CC</td>\n",
       "      <td id=\"T_a9c25_row29_col4\" class=\"data row29 col4\" >cc</td>\n",
       "      <td id=\"T_a9c25_row29_col5\" class=\"data row29 col5\" >True</td>\n",
       "      <td id=\"T_a9c25_row29_col6\" class=\"data row29 col6\" >False</td>\n",
       "      <td id=\"T_a9c25_row29_col7\" class=\"data row29 col7\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9c25_level0_row30\" class=\"row_heading level0 row30\" >30</th>\n",
       "      <td id=\"T_a9c25_row30_col0\" class=\"data row30 col0\" >sadly</td>\n",
       "      <td id=\"T_a9c25_row30_col1\" class=\"data row30 col1\" >sadly</td>\n",
       "      <td id=\"T_a9c25_row30_col2\" class=\"data row30 col2\" >ADV</td>\n",
       "      <td id=\"T_a9c25_row30_col3\" class=\"data row30 col3\" >RB</td>\n",
       "      <td id=\"T_a9c25_row30_col4\" class=\"data row30 col4\" >advmod</td>\n",
       "      <td id=\"T_a9c25_row30_col5\" class=\"data row30 col5\" >False</td>\n",
       "      <td id=\"T_a9c25_row30_col6\" class=\"data row30 col6\" >False</td>\n",
       "      <td id=\"T_a9c25_row30_col7\" class=\"data row30 col7\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9c25_level0_row31\" class=\"row_heading level0 row31\" >31</th>\n",
       "      <td id=\"T_a9c25_row31_col0\" class=\"data row31 col0\" >expired</td>\n",
       "      <td id=\"T_a9c25_row31_col1\" class=\"data row31 col1\" >expire</td>\n",
       "      <td id=\"T_a9c25_row31_col2\" class=\"data row31 col2\" >VERB</td>\n",
       "      <td id=\"T_a9c25_row31_col3\" class=\"data row31 col3\" >VBD</td>\n",
       "      <td id=\"T_a9c25_row31_col4\" class=\"data row31 col4\" >advcl</td>\n",
       "      <td id=\"T_a9c25_row31_col5\" class=\"data row31 col5\" >False</td>\n",
       "      <td id=\"T_a9c25_row31_col6\" class=\"data row31 col6\" >False</td>\n",
       "      <td id=\"T_a9c25_row31_col7\" class=\"data row31 col7\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9c25_level0_row32\" class=\"row_heading level0 row32\" >32</th>\n",
       "      <td id=\"T_a9c25_row32_col0\" class=\"data row32 col0\" >this</td>\n",
       "      <td id=\"T_a9c25_row32_col1\" class=\"data row32 col1\" >this</td>\n",
       "      <td id=\"T_a9c25_row32_col2\" class=\"data row32 col2\" >DET</td>\n",
       "      <td id=\"T_a9c25_row32_col3\" class=\"data row32 col3\" >DT</td>\n",
       "      <td id=\"T_a9c25_row32_col4\" class=\"data row32 col4\" >det</td>\n",
       "      <td id=\"T_a9c25_row32_col5\" class=\"data row32 col5\" >True</td>\n",
       "      <td id=\"T_a9c25_row32_col6\" class=\"data row32 col6\" >False</td>\n",
       "      <td id=\"T_a9c25_row32_col7\" class=\"data row32 col7\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9c25_level0_row33\" class=\"row_heading level0 row33\" >33</th>\n",
       "      <td id=\"T_a9c25_row33_col0\" class=\"data row33 col0\" >gloomy</td>\n",
       "      <td id=\"T_a9c25_row33_col1\" class=\"data row33 col1\" >gloomy</td>\n",
       "      <td id=\"T_a9c25_row33_col2\" class=\"data row33 col2\" >ADJ</td>\n",
       "      <td id=\"T_a9c25_row33_col3\" class=\"data row33 col3\" >JJ</td>\n",
       "      <td id=\"T_a9c25_row33_col4\" class=\"data row33 col4\" >dobj</td>\n",
       "      <td id=\"T_a9c25_row33_col5\" class=\"data row33 col5\" >False</td>\n",
       "      <td id=\"T_a9c25_row33_col6\" class=\"data row33 col6\" >False</td>\n",
       "      <td id=\"T_a9c25_row33_col7\" class=\"data row33 col7\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9c25_level0_row34\" class=\"row_heading level0 row34\" >34</th>\n",
       "      <td id=\"T_a9c25_row34_col0\" class=\"data row34 col0\" >tuesday</td>\n",
       "      <td id=\"T_a9c25_row34_col1\" class=\"data row34 col1\" >tuesday</td>\n",
       "      <td id=\"T_a9c25_row34_col2\" class=\"data row34 col2\" >PROPN</td>\n",
       "      <td id=\"T_a9c25_row34_col3\" class=\"data row34 col3\" >NNP</td>\n",
       "      <td id=\"T_a9c25_row34_col4\" class=\"data row34 col4\" >npadvmod</td>\n",
       "      <td id=\"T_a9c25_row34_col5\" class=\"data row34 col5\" >False</td>\n",
       "      <td id=\"T_a9c25_row34_col6\" class=\"data row34 col6\" >False</td>\n",
       "      <td id=\"T_a9c25_row34_col7\" class=\"data row34 col7\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9c25_level0_row35\" class=\"row_heading level0 row35\" >35</th>\n",
       "      <td id=\"T_a9c25_row35_col0\" class=\"data row35 col0\" >at</td>\n",
       "      <td id=\"T_a9c25_row35_col1\" class=\"data row35 col1\" >at</td>\n",
       "      <td id=\"T_a9c25_row35_col2\" class=\"data row35 col2\" >ADP</td>\n",
       "      <td id=\"T_a9c25_row35_col3\" class=\"data row35 col3\" >IN</td>\n",
       "      <td id=\"T_a9c25_row35_col4\" class=\"data row35 col4\" >prep</td>\n",
       "      <td id=\"T_a9c25_row35_col5\" class=\"data row35 col5\" >True</td>\n",
       "      <td id=\"T_a9c25_row35_col6\" class=\"data row35 col6\" >False</td>\n",
       "      <td id=\"T_a9c25_row35_col7\" class=\"data row35 col7\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9c25_level0_row36\" class=\"row_heading level0 row36\" >36</th>\n",
       "      <td id=\"T_a9c25_row36_col0\" class=\"data row36 col0\" >the</td>\n",
       "      <td id=\"T_a9c25_row36_col1\" class=\"data row36 col1\" >the</td>\n",
       "      <td id=\"T_a9c25_row36_col2\" class=\"data row36 col2\" >DET</td>\n",
       "      <td id=\"T_a9c25_row36_col3\" class=\"data row36 col3\" >DT</td>\n",
       "      <td id=\"T_a9c25_row36_col4\" class=\"data row36 col4\" >det</td>\n",
       "      <td id=\"T_a9c25_row36_col5\" class=\"data row36 col5\" >True</td>\n",
       "      <td id=\"T_a9c25_row36_col6\" class=\"data row36 col6\" >False</td>\n",
       "      <td id=\"T_a9c25_row36_col7\" class=\"data row36 col7\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9c25_level0_row37\" class=\"row_heading level0 row37\" >37</th>\n",
       "      <td id=\"T_a9c25_row37_col0\" class=\"data row37 col0\" >age</td>\n",
       "      <td id=\"T_a9c25_row37_col1\" class=\"data row37 col1\" >age</td>\n",
       "      <td id=\"T_a9c25_row37_col2\" class=\"data row37 col2\" >NOUN</td>\n",
       "      <td id=\"T_a9c25_row37_col3\" class=\"data row37 col3\" >NN</td>\n",
       "      <td id=\"T_a9c25_row37_col4\" class=\"data row37 col4\" >pobj</td>\n",
       "      <td id=\"T_a9c25_row37_col5\" class=\"data row37 col5\" >False</td>\n",
       "      <td id=\"T_a9c25_row37_col6\" class=\"data row37 col6\" >False</td>\n",
       "      <td id=\"T_a9c25_row37_col7\" class=\"data row37 col7\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9c25_level0_row38\" class=\"row_heading level0 row38\" >38</th>\n",
       "      <td id=\"T_a9c25_row38_col0\" class=\"data row38 col0\" >of</td>\n",
       "      <td id=\"T_a9c25_row38_col1\" class=\"data row38 col1\" >of</td>\n",
       "      <td id=\"T_a9c25_row38_col2\" class=\"data row38 col2\" >ADP</td>\n",
       "      <td id=\"T_a9c25_row38_col3\" class=\"data row38 col3\" >IN</td>\n",
       "      <td id=\"T_a9c25_row38_col4\" class=\"data row38 col4\" >prep</td>\n",
       "      <td id=\"T_a9c25_row38_col5\" class=\"data row38 col5\" >True</td>\n",
       "      <td id=\"T_a9c25_row38_col6\" class=\"data row38 col6\" >False</td>\n",
       "      <td id=\"T_a9c25_row38_col7\" class=\"data row38 col7\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9c25_level0_row39\" class=\"row_heading level0 row39\" >39</th>\n",
       "      <td id=\"T_a9c25_row39_col0\" class=\"data row39 col0\" >87</td>\n",
       "      <td id=\"T_a9c25_row39_col1\" class=\"data row39 col1\" >87</td>\n",
       "      <td id=\"T_a9c25_row39_col2\" class=\"data row39 col2\" >NUM</td>\n",
       "      <td id=\"T_a9c25_row39_col3\" class=\"data row39 col3\" >CD</td>\n",
       "      <td id=\"T_a9c25_row39_col4\" class=\"data row39 col4\" >nummod</td>\n",
       "      <td id=\"T_a9c25_row39_col5\" class=\"data row39 col5\" >False</td>\n",
       "      <td id=\"T_a9c25_row39_col6\" class=\"data row39 col6\" >False</td>\n",
       "      <td id=\"T_a9c25_row39_col7\" class=\"data row39 col7\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9c25_level0_row40\" class=\"row_heading level0 row40\" >40</th>\n",
       "      <td id=\"T_a9c25_row40_col0\" class=\"data row40 col0\" >years</td>\n",
       "      <td id=\"T_a9c25_row40_col1\" class=\"data row40 col1\" >year</td>\n",
       "      <td id=\"T_a9c25_row40_col2\" class=\"data row40 col2\" >NOUN</td>\n",
       "      <td id=\"T_a9c25_row40_col3\" class=\"data row40 col3\" >NNS</td>\n",
       "      <td id=\"T_a9c25_row40_col4\" class=\"data row40 col4\" >npadvmod</td>\n",
       "      <td id=\"T_a9c25_row40_col5\" class=\"data row40 col5\" >False</td>\n",
       "      <td id=\"T_a9c25_row40_col6\" class=\"data row40 col6\" >False</td>\n",
       "      <td id=\"T_a9c25_row40_col7\" class=\"data row40 col7\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9c25_level0_row41\" class=\"row_heading level0 row41\" >41</th>\n",
       "      <td id=\"T_a9c25_row41_col0\" class=\"data row41 col0\" >old</td>\n",
       "      <td id=\"T_a9c25_row41_col1\" class=\"data row41 col1\" >old</td>\n",
       "      <td id=\"T_a9c25_row41_col2\" class=\"data row41 col2\" >ADJ</td>\n",
       "      <td id=\"T_a9c25_row41_col3\" class=\"data row41 col3\" >JJ</td>\n",
       "      <td id=\"T_a9c25_row41_col4\" class=\"data row41 col4\" >acomp</td>\n",
       "      <td id=\"T_a9c25_row41_col5\" class=\"data row41 col5\" >False</td>\n",
       "      <td id=\"T_a9c25_row41_col6\" class=\"data row41 col6\" >False</td>\n",
       "      <td id=\"T_a9c25_row41_col7\" class=\"data row41 col7\" >False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x19a72ede130>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdf = pd.DataFrame(\n",
    "{\n",
    "    'token': [w.text for w in tokenCollection ],\n",
    "    'lemma': [w.lemma_ for w in tokenCollection],\n",
    "    'POS'  : [w.pos_ for w in tokenCollection],\n",
    "    'TAG'  : [w.tag_ for w in tokenCollection],\n",
    "    'DEP' : [w.dep_ for w in tokenCollection],\n",
    "    'is_stopword' : [w.is_stop for w in tokenCollection],\n",
    "    'is_punctuation' : [w.is_punct for w in tokenCollection],\n",
    "    'is_digit' : [w.is_digit for w in tokenCollection]\n",
    "})\n",
    "\n",
    "def highlight_True(s):\n",
    "    \"\"\"\n",
    "    Highlight True and False\n",
    "    \"\"\"\n",
    "    return ['background-color:orange' if v else '' for v in s]\n",
    "newdf.style.apply(highlight_True,subset = ['is_stopword','is_punctuation','is_digit'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7ef9b2",
   "metadata": {},
   "source": [
    "## Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c90b5189",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(df):\n",
    "    \n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    for i in range(df.shape[0]):\n",
    "        tokenCollection = nlp(df['headline'][i])\n",
    "        tokenList = [token.lemma_.lower().strip() for token in tokenCollection\n",
    "                if not (token.is_stop | token.is_punct | token.is_digit)]\n",
    "        text = \" \".join(tokenList)\n",
    "        \n",
    "        if i <5: print('Sentence:',i,text)\n",
    "        df['headline'][i] = text\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9d3283cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26709, 4)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a8df21f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: 0 versace store clerk sue secret black code minority shopper\n",
      "                                            article_link  \\\n",
      "0      https://www.huffingtonpost.com/entry/versace-b...   \n",
      "1      https://www.huffingtonpost.com/entry/roseanne-...   \n",
      "2      https://local.theonion.com/mom-starting-to-fea...   \n",
      "3      https://politics.theonion.com/boehner-just-wan...   \n",
      "4      https://www.huffingtonpost.com/entry/jk-rowlin...   \n",
      "...                                                  ...   \n",
      "26704  https://www.huffingtonpost.com/entry/american-...   \n",
      "26705  https://www.huffingtonpost.com/entry/americas-...   \n",
      "26706  https://www.huffingtonpost.com/entry/reparatio...   \n",
      "26707  https://www.huffingtonpost.com/entry/israeli-b...   \n",
      "26708  https://www.huffingtonpost.com/entry/gourmet-g...   \n",
      "\n",
      "                                                headline  is_sarcastic  \\\n",
      "0      versace store clerk sue secret black code mino...             0   \n",
      "1      the 'roseanne' revival catches up to our thorn...             0   \n",
      "2      mom starting to fear son's web series closest ...             1   \n",
      "3      boehner just wants wife to listen, not come up...             1   \n",
      "4      j.k. rowling wishes snape happy birthday in th...             0   \n",
      "...                                                  ...           ...   \n",
      "26704               american politics in moral free-fall             0   \n",
      "26705                            america's best 20 hikes             0   \n",
      "26706                              reparations and obama             0   \n",
      "26707  israeli ban targeting boycott supporters raise...             0   \n",
      "26708                  gourmet gifts for the foodie 2014             0   \n",
      "\n",
      "       num_words  \n",
      "0             12  \n",
      "1             14  \n",
      "2             14  \n",
      "3             13  \n",
      "4             11  \n",
      "...          ...  \n",
      "26704          5  \n",
      "26705          4  \n",
      "26706          3  \n",
      "26707          8  \n",
      "26708          6  \n",
      "\n",
      "[26709 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shivani Dussa\\AppData\\Local\\Temp\\ipykernel_11096\\3996204860.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['headline'][i] = text\n"
     ]
    }
   ],
   "source": [
    "news_df = clean_text(df)\n",
    "print(news_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccef642e",
   "metadata": {},
   "source": [
    "### Implement TFIDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5b2687b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tf = TfidfVectorizer(analyzer = 'word',ngram_range = (1,3),max_features = 3000)   # there are 26k headlines we are taking 3k\n",
    "X = tf.fit_transform(news_df['headline'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "399389b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26709, 3000), scipy.sparse.csr.csr_matrix)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "de2af1a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'versace store clerk sue secret black code minority shopper'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['headline'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b4e72152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"what's in your mailbox? tips on what to do when uncle sam comes knocking\""
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['headline'][26700]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c75f4d",
   "metadata": {},
   "source": [
    "### **Splitting the data into training and testing set using train_test_split function from sklearn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c595b0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = news_df['is_sarcastic']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3,random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f794c6",
   "metadata": {},
   "source": [
    "### Model Building "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0a1b89a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creaeting a model object\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "nb = BernoulliNB()\n",
    "\n",
    "#Fitting the model on the training dataset\n",
    "nb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9043b6f8",
   "metadata": {},
   "source": [
    "### **Model Evaluvation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "58d2f798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      " [[3704  740]\n",
      " [ 628 2941]]\n"
     ]
    }
   ],
   "source": [
    "pred = nb.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "print('Confusion matrix\\n',confusion_matrix(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0764fc49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80127"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0ec00287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6645"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3704+2941"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "288cbad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import  accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "roc = roc_auc_score(y_test,pred)\n",
    "acc = accuracy_score(y_test,pred)\n",
    "prec = precision_score(y_test,pred)\n",
    "recall = recall_score(y_test,pred)\n",
    "f1 = f1_score(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d58ea802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bernoulli Classifier</td>\n",
       "      <td>0.829277</td>\n",
       "      <td>0.798968</td>\n",
       "      <td>0.82404</td>\n",
       "      <td>0.81131</td>\n",
       "      <td>0.828762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  Accuracy  Precision   Recall  F1 Score       ROC\n",
       "0  Bernoulli Classifier  0.829277   0.798968  0.82404   0.81131  0.828762"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame([['Bernoulli Classifier', acc,prec,recall, f1,roc],\n",
    "                        ],\n",
    "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score','ROC'])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3cf9ce3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report\n",
      ":               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.83      0.84      4444\n",
      "           1       0.80      0.82      0.81      3569\n",
      "\n",
      "    accuracy                           0.83      8013\n",
      "   macro avg       0.83      0.83      0.83      8013\n",
      "weighted avg       0.83      0.83      0.83      8013\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('classification report\\n:', classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bc8e12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
